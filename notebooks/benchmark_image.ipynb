{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fae3b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST, ImageFolder\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b22073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Hiperparameters---\n",
    "ROOT = Path(\"../data\")\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5427e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "É módulo: True\n"
     ]
    }
   ],
   "source": [
    "print(\"É módulo:\", isinstance(T, type(T)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "074688f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure transforms mnist\n",
    "def mnist_loaders():\n",
    "    tf_train = T.Compose([T.RandomRotation(10),\n",
    "                                   T.ToTensor(),\n",
    "                                   T.Normalize((0.1307,), (0.3081,))])\n",
    "    tf_test  = T.Compose([T.ToTensor(),\n",
    "                                   T.Normalize((0.1307,), (0.3081,))])\n",
    "    tr = MNIST(\n",
    "        root=ROOT,\n",
    "        train=True,\n",
    "        transform=tf_train,\n",
    "        download=True\n",
    "     )\n",
    "    te = MNIST(\n",
    "        root=ROOT,\n",
    "        train=False,\n",
    "        transform=tf_test,\n",
    "        download=True\n",
    "     )\n",
    "    return (DataLoader(tr, BATCH_SIZE, True,  num_workers=NUM_WORKERS),\n",
    "            DataLoader(te, BATCH_SIZE*4, False, num_workers=NUM_WORKERS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1d56321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure transforms cifar10\n",
    "def cifar10_loaders():\n",
    "    tf_train = T.Compose([T.Grayscale(),\n",
    "                                   T.RandomHorizontalFlip(),\n",
    "                                   T.RandomRotation(10),\n",
    "                                   T.Resize((28,28)),\n",
    "                                   T.ToTensor(),\n",
    "                                   T.Normalize((0.5,), (0.5,))])\n",
    "    tf_test  = T.Compose([T.Grayscale(),\n",
    "                                   T.Resize((28,28)),\n",
    "                                   T.ToTensor(),\n",
    "                                   T.Normalize((0.5,), (0.5,))])\n",
    "    tr = CIFAR10(ROOT, True,  True, tf_train)\n",
    "    te = CIFAR10(ROOT, False, True, tf_test)\n",
    "    return (DataLoader(tr, BATCH_SIZE, True,  num_workers=NUM_WORKERS),\n",
    "            DataLoader(te, BATCH_SIZE*4, False, num_workers=NUM_WORKERS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f2af534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medical_loaders():\n",
    "    med_root = ROOT/\"medical_mnist\"             # baixe via Kaggle antes!\n",
    "    tf_train = T.Compose([T.Grayscale(),\n",
    "                                   T.RandomRotation(10),\n",
    "                                   T.RandomHorizontalFlip(),\n",
    "                                   T.Resize((64,64)),\n",
    "                                   T.ToTensor(),\n",
    "                                   T.Normalize((0.5,), (0.5,))])\n",
    "    tf_test  = T.Compose([T.Grayscale(),\n",
    "                                   T.Resize((64,64)),\n",
    "                                   T.ToTensor(),\n",
    "                                   T.Normalize((0.5,), (0.5,))])\n",
    "    full = ImageFolder(med_root, transform=tf_train)\n",
    "    tr_len, te_len = 47163, len(full)-47163\n",
    "    tr, te = random_split(full, [tr_len, te_len],\n",
    "                          generator=torch.Generator().manual_seed(42))\n",
    "    te.dataset.transform = tf_test\n",
    "    return (DataLoader(tr, BATCH_SIZE, True,  num_workers=NUM_WORKERS),\n",
    "            DataLoader(te, BATCH_SIZE*4, False, num_workers=NUM_WORKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1180547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanv_pqc():\n",
    "    import pennylane as qml\n",
    "    dev = qml.device(\"lightning.qubit\", wires=4)\n",
    "\n",
    "    @qml.qnode(dev, interface=\"torch\", diff_method=\"adjoint\")\n",
    "    def circuit(inputs, weights):            # inputs: (batch, 4)\n",
    "        # 1) Y-encoding batelado\n",
    "        qml.AngleEmbedding(\n",
    "            features=inputs, wires=range(4), rotation=\"Y\")\n",
    "\n",
    "        qml.RX(weights[0], wires=0)\n",
    "        qml.RX(weights[1], wires=1)\n",
    "        # 3) Triângulo de CNOTs (4→3, 3→1, 4→1)\n",
    "        qml.CNOT(wires=[3, 2])\n",
    "        qml.CNOT(wires=[2, 0])\n",
    "        qml.CNOT(wires=[3, 0])\n",
    "\n",
    "        # 4) Y-gates apenas nos fios 0 e 3\n",
    "        qml.RY(weights[2], wires=0)\n",
    "        qml.RY(weights[3], wires=3)\n",
    "\n",
    "        # expval de Z em cada qubit  →   (batch, 4)\n",
    "        return [qml.expval(qml.PauliZ(k)) for k in range(4)]\n",
    "\n",
    "    return qml.qnn.TorchLayer(circuit,\n",
    "                              weight_shapes={\"weights\": (4,)})\n",
    "\n",
    "\n",
    "\n",
    "class QuanvLayer(nn.Module):\n",
    "    def __init__(self, patch=2):\n",
    "        super().__init__()\n",
    "        self.patch = patch\n",
    "        self.pqc = quanv_pqc()\n",
    "\n",
    "    def forward(self, x):                     # B×1×H×W\n",
    "        B, _, H, W = x.shape\n",
    "        px = (x.unfold(2, self.patch, self.patch)\n",
    "                .unfold(3, self.patch, self.patch)          # B×1×H'×W'×2×2\n",
    "                .contiguous()\n",
    "                .view(-1, self.patch**2))                  # (B·H'·W')×4\n",
    "\n",
    "        # normalização *por patch*\n",
    "        px_min, px_max = px.min(dim=1, keepdim=True).values, px.max(dim=1, keepdim=True).values\n",
    "        px = (px - px_min) / (px_max - px_min + 1e-8) * torch.pi\n",
    "\n",
    "        z = self.pqc(px)                                   # (B·H'·W')×4\n",
    "        z = z.view(B, H//self.patch, W//self.patch, 4).permute(0,3,1,2)\n",
    "        return z.contiguous()                              # B×4×H'×W'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e727e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HQuanvNet10(nn.Module):                       # MNIST & CIFAR-10\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pre = nn.Sequential(                   # cinza + 28×28\n",
    "            T.Grayscale(num_output_channels=1),\n",
    "            T.Resize((28, 28))\n",
    "        )\n",
    "        self.quanv = QuanvLayer()\n",
    "        self.fc = nn.Linear(4*14*14, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():           # transforms funciona em tensor?\n",
    "            x = torch.stack([self.pre(img) for img in x])  # minibatch loop\n",
    "        x = self.quanv(x)\n",
    "        return self.fc(x.flatten(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c531897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HQuanvNet6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resize = T.Resize((28, 28))\n",
    "        self.gray   = T.Grayscale()\n",
    "        self.quanv  = QuanvLayer()                 # seu bloco corrigido\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(4 * 14 * 14, 6)        # 6 categorias\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x B×3×64×64  (Medical MNIST)\n",
    "        x = self.gray(x)                           # → B×1×64×64\n",
    "        x = self.resize(x)                         # → B×1×28×28\n",
    "        x = self.quanv(x)                          # → B×4×14×14\n",
    "        x = self.flatten(x)                        # → B×784\n",
    "        return self.fc(x)                          # → B×6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e8fed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HQuanvNet6(nn.Module):                        # Medical MNIST\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pre = nn.Sequential(\n",
    "            T.Grayscale(1),\n",
    "            T.Resize((28, 28))\n",
    "        )\n",
    "        self.quanv = QuanvLayer()\n",
    "        self.fc = nn.Linear(4*14*14, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = torch.stack([self.pre(img) for img in x])\n",
    "        x = self.quanv(x)\n",
    "        return self.fc(x.flatten(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feacd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\"mnist\": HQuanvNet10, \"cifar10\": HQuanvNet10, \"medical\": HQuanvNet6}\n",
    "LOADERS = {\"mnist\": mnist_loaders, \"cifar10\": cifar10_loaders, \"medical\": medical_loaders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71ab2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(dataset_name, epochs=10, lr=1e-3, device=\"cuda\"):\n",
    "    device = device if torch.cuda.is_available() else \"cpu\"\n",
    "    train_dl, test_dl = LOADERS[dataset_name]()\n",
    "    print(f\"Treinando {dataset_name} com {device}...\")\n",
    "    model = MODELS[dataset_name]().to(device)\n",
    "    print(f\"Modelo: {model.__class__.__name__} ({sum(p.numel() for p in model.parameters())} parâmetros)\")\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print(f\"Otimizador: {opt.__class__.__name__} (lr={lr})\")\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    print(f\"Função de perda: {loss_fn.__class__.__name__}\")\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(f\"Iniciando época {ep+1}/{epochs}...\")\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            print(f\"Processando lote: {xb.shape} (rótulos: {yb.shape})\")\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            # forward + backward + step\n",
    "            # xb: B×C×H×W, yb: B\n",
    "            loss_fn(model(xb), yb).backward()\n",
    "            print(f\"Perda: {loss_fn(model(xb), yb).item():.4f}\")\n",
    "            opt.step()\n",
    "            print(\"Gradientes atualizados\")\n",
    "        # fim da época\n",
    "        print(f\"[{dataset_name}] época {ep+1}/{epochs} concluída\")\n",
    "\n",
    "    # avaliação\n",
    "    model.eval(); correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dl:\n",
    "            pred = model(xb.to(device)).argmax(1).cpu()\n",
    "            correct += (pred == yb).sum().item(); total += yb.size(0)\n",
    "    print(f\"[{dataset_name}] Acurácia teste: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6707ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando mnist com cpu...\n",
      "Modelo: HQuanvNet10 (7854 parâmetros)\n",
      "Otimizador: Adam (lr=0.001)\n",
      "Função de perda: CrossEntropyLoss\n",
      "Iniciando época 1/10...\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.3438\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.3167\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.2774\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.3735\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.1949\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.1748\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.0909\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.0958\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.0706\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.0340\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.0503\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 2.0762\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.9913\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.9511\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.8199\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.8399\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.8672\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.7786\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.7787\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.7948\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.7625\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.7125\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.7058\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.6286\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.5523\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.6326\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.6086\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.6391\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.4816\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.5761\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.5411\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.4189\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.4476\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3381\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.4356\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.2556\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.4286\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3864\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3428\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.2253\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3358\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.2398\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3810\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.2167\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3406\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1117\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.3365\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1601\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1962\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1510\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1827\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0875\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1054\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1951\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0384\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9685\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9124\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.2067\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9922\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0490\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1258\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0727\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0598\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1050\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0291\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9754\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8715\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9159\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.1074\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8594\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8715\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0702\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8926\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9720\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0483\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8022\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0241\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9191\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6802\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8907\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8622\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9230\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8523\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8280\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 1.0021\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8747\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8699\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6691\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9725\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8488\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8785\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7924\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8472\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7228\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7625\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8084\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6889\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7944\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.9645\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6902\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6874\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7325\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8279\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7164\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6964\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7032\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7795\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6723\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6717\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7694\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7423\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.7565\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6588\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.8007\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6482\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n",
      "Perda: 0.6915\n",
      "Gradientes atualizados\n",
      "Processando lote: torch.Size([64, 1, 28, 28]) (rótulos: torch.Size([64]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mmnist\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcifar10\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmedical\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[43mtrain_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_one\u001b[39m\u001b[34m(dataset_name, epochs, lr, device)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# forward + backward + step\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# xb: B×C×H×W, yb: B\u001b[39;00m\n\u001b[32m     21\u001b[39m loss_fn(model(xb), yb).backward()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerda: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_fn(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;250m \u001b[39myb).item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m opt.step()\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGradientes atualizados\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mHQuanvNet10.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():           \u001b[38;5;66;03m# transforms funciona em tensor?\u001b[39;00m\n\u001b[32m     13\u001b[39m     x = torch.stack([\u001b[38;5;28mself\u001b[39m.pre(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m x])  \u001b[38;5;66;03m# minibatch loop\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquanv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(x.flatten(\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mQuanvLayer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     44\u001b[39m px_min, px_max = px.min(dim=\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m).values, px.max(dim=\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m).values\n\u001b[32m     45\u001b[39m px = (px - px_min) / (px_max - px_min + \u001b[32m1e-8\u001b[39m) * torch.pi\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpqc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpx\u001b[49m\u001b[43m)\u001b[49m                                   \u001b[38;5;66;03m# (B·H'·W')×4\u001b[39;00m\n\u001b[32m     48\u001b[39m z = z.view(B, H//\u001b[38;5;28mself\u001b[39m.patch, W//\u001b[38;5;28mself\u001b[39m.patch, \u001b[32m4\u001b[39m).permute(\u001b[32m0\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m z.contiguous()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\qnn\\torch.py:404\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    401\u001b[39m     inputs = torch.reshape(inputs, (-\u001b[32m1\u001b[39m, inputs.shape[-\u001b[32m1\u001b[39m]))\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\qnn\\torch.py:430\u001b[39m, in \u001b[36mTorchLayer._evaluate_qnode\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[32m    419\u001b[39m \n\u001b[32m    420\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    424\u001b[39m \u001b[33;03m    tensor: output datapoint\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m kwargs = {\n\u001b[32m    427\u001b[39m     **{\u001b[38;5;28mself\u001b[39m.input_arg: x},\n\u001b[32m    428\u001b[39m     **{arg: weight.to(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.qnode_weights.items()},\n\u001b[32m    429\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch.Tensor):\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.type(x.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:882\u001b[39m, in \u001b[36mQNode.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    879\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_capture_qnode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:855\u001b[39m, in \u001b[36mQNode._impl_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[32m    853\u001b[39m \u001b[38;5;28mself\u001b[39m._transform_program.set_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m res = \u001b[43mqml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    864\u001b[39m res = res[\u001b[32m0\u001b[39m]\n\u001b[32m    866\u001b[39m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\execution.py:244\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(tapes, device, diff_method, interface, transform_program, grad_on_execution, cache, cachesize, max_diff, device_vjp, postselect_mode, mcm_method, gradient_kwargs, mcm_config, config, inner_transform)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transform_program.is_informative:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(tapes)\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m results = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\run.py:332\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(tapes, device, config, inner_transform_program)\u001b[39m\n\u001b[32m    329\u001b[39m         params = tape.get_parameters(trainable_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    330\u001b[39m         tape.trainable_params = qml.math.get_trainable_indices(params)\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m results = \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:236\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(tapes, execute_fn, jpc, device)\u001b[39m\n\u001b[32m    228\u001b[39m     parameters.extend(tape.get_parameters())\n\u001b[32m    230\u001b[39m kwargs = {\n\u001b[32m    231\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtapes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mexecute_fn\u001b[39m\u001b[33m\"\u001b[39m: execute_fn,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjpc\u001b[39m\u001b[33m\"\u001b[39m: jpc,\n\u001b[32m    234\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:89\u001b[39m, in \u001b[36mpytreeify.<locals>.new_apply\u001b[39m\u001b[34m(*inp)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_apply\u001b[39m(*inp):\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[32m     88\u001b[39m     out_struct_holder = []\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     flat_out = \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree.tree_unflatten(flat_out, out_struct_holder[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:93\u001b[39m, in \u001b[36mpytreeify.<locals>.new_forward\u001b[39m\u001b[34m(ctx, out_struct_holder, *inp)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(ctx, out_struct_holder, *inp):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     out = \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     flat_out, out_struct = pytree.tree_flatten(out)\n\u001b[32m     95\u001b[39m     ctx._out_struct = out_struct\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:158\u001b[39m, in \u001b[36mExecuteTapes.forward\u001b[39m\u001b[34m(ctx, kwargs, *parameters)\u001b[39m\n\u001b[32m    155\u001b[39m ctx.tapes = kwargs[\u001b[33m\"\u001b[39m\u001b[33mtapes\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    156\u001b[39m ctx.jpc = kwargs[\u001b[33m\"\u001b[39m\u001b[33mjpc\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m res = \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexecute_fn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[32m    161\u001b[39m ctx.torch_device = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:482\u001b[39m, in \u001b[36mDeviceDerivatives.execute_and_cache_jacobian\u001b[39m\u001b[34m(self, tapes)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logger.isEnabledFor(logging.DEBUG):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    481\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mForward pass called with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, tapes)\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m results, jac = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dev_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[38;5;28mself\u001b[39m._results_cache[tapes] = results\n\u001b[32m    484\u001b[39m \u001b[38;5;28mself\u001b[39m._jacs_cache[tapes] = jac\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:447\u001b[39m, in \u001b[36mDeviceDerivatives._dev_execute_and_compute_derivatives\u001b[39m\u001b[34m(self, tapes)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    442\u001b[39m \u001b[33;03mConverts tapes to numpy before computing the the results and derivatives on the device.\u001b[39;00m\n\u001b[32m    443\u001b[39m \n\u001b[32m    444\u001b[39m \u001b[33;03mDispatches between the two different device interfaces.\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    446\u001b[39m numpy_tapes, _ = qml.transforms.convert_to_numpy_parameters(tapes)\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_device\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py:95\u001b[39m, in \u001b[36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracker.update(\n\u001b[32m     90\u001b[39m         execute_and_derivative_batches=\u001b[32m1\u001b[39m,\n\u001b[32m     91\u001b[39m         executions=\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[32m     92\u001b[39m         derivatives=\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[32m     93\u001b[39m     )\n\u001b[32m     94\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracker.record()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py:60\u001b[39m, in \u001b[36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     58\u001b[39m     is_single_circuit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     59\u001b[39m     circuits = (circuits,)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m results, jacs = \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[32m0\u001b[39m], jacs[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py:95\u001b[39m, in \u001b[36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracker.update(\n\u001b[32m     90\u001b[39m         execute_and_derivative_batches=\u001b[32m1\u001b[39m,\n\u001b[32m     91\u001b[39m         executions=\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[32m     92\u001b[39m         derivatives=\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[32m     93\u001b[39m     )\n\u001b[32m     94\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracker.record()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py:60\u001b[39m, in \u001b[36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m     58\u001b[39m     is_single_circuit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     59\u001b[39m     circuits = (circuits,)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m results, jacs = \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[32m0\u001b[39m], jacs[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_base.py:377\u001b[39m, in \u001b[36mLightningBase.execute_and_compute_derivatives\u001b[39m\u001b[34m(self, circuits, execution_config)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[32m    368\u001b[39m \n\u001b[32m    369\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m \u001b[33;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    376\u001b[39m batch_obs = execution_config.device_options.get(\u001b[33m\"\u001b[39m\u001b[33mbatch_obs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._batch_obs)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m results = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m.simulate_and_jacobian(\n\u001b[32m    379\u001b[39m         \u001b[38;5;28mself\u001b[39m.dynamic_wires_from_circuit(circuit),\n\u001b[32m    380\u001b[39m         \u001b[38;5;28mself\u001b[39m._statevector,\n\u001b[32m    381\u001b[39m         batch_obs=batch_obs,\n\u001b[32m    382\u001b[39m         wire_map=\u001b[38;5;28mself\u001b[39m._wire_map,\n\u001b[32m    383\u001b[39m     )\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[32m    385\u001b[39m )\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*results))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_base.py:378\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[32m    368\u001b[39m \n\u001b[32m    369\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m \u001b[33;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    376\u001b[39m batch_obs = execution_config.device_options.get(\u001b[33m\"\u001b[39m\u001b[33mbatch_obs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._batch_obs)\n\u001b[32m    377\u001b[39m results = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdynamic_wires_from_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wire_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[32m    385\u001b[39m )\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*results))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_base.py:268\u001b[39m, in \u001b[36mLightningBase.simulate_and_jacobian\u001b[39m\u001b[34m(self, circuit, state, batch_obs, wire_map)\u001b[39m\n\u001b[32m    266\u001b[39m res = \u001b[38;5;28mself\u001b[39m.simulate(circuit, state)\n\u001b[32m    267\u001b[39m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m jac = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mLightningAdjointJacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res, jac\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane_lightning\\lightning_qubit\\_adjoint_jacobian.py:132\u001b[39m, in \u001b[36mLightningAdjointJacobian.calculate_jacobian\u001b[39m\u001b[34m(self, tape)\u001b[39m\n\u001b[32m    130\u001b[39m jac_r = np.zeros((jac.shape[\u001b[32m0\u001b[39m], processed_data[\u001b[33m\"\u001b[39m\u001b[33mall_params\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m    131\u001b[39m jac_r[:, processed_data[\u001b[33m\"\u001b[39m\u001b[33mrecord_tp_rows\u001b[39m\u001b[33m\"\u001b[39m]] = jac\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adjoint_jacobian_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_r\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Trabalho_individual\\trabalho_individual\\.venv\\Lib\\site-packages\\pennylane_lightning\\core\\_adjoint_jacobian_base.py:153\u001b[39m, in \u001b[36mLightningBaseAdjointJacobian._adjoint_jacobian_processing\u001b[39m\u001b[34m(jac)\u001b[39m\n\u001b[32m    141\u001b[39m         tp_shift = [i - \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tp_shift]\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstate_vector\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.state,\n\u001b[32m    145\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mobs_serialized\u001b[39m\u001b[33m\"\u001b[39m: obs_serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mobs_indices\u001b[39m\u001b[33m\"\u001b[39m: obs_indices,\n\u001b[32m    151\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_adjoint_jacobian_processing\u001b[39m(jac):\n\u001b[32m    155\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    Post-process the Jacobian matrix returned by ``adjoint_jacobian`` for\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m    the new return type system.\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m     jac = np.squeeze(jac)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for ds in (\"mnist\", \"cifar10\", \"medical\"):\n",
    "        train_one(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a4a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
