{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429a44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from stable_baselines3 import PPO\n",
    "from medmnist import ChestMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3dd9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED   = 42\n",
    "torch.manual_seed(SEED)  \n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bbbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SZ = 64\n",
    "IMG_SIZE  = 32   \n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d398bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b180c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ChestMNIST(split=\"train\", download=True, as_rgb=True, transform=transform)\n",
    "test  = ChestMNIST(split=\"test\", download=True, as_rgb=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "820b2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apenas 3 classes classificadas nesse momento\n",
    "train_idx = [i for i,(x,y) in enumerate(train) if y[0] < NUM_CLASSES]\n",
    "test_idx  = [i for i,(x,y) in enumerate(test)  if y[0] < NUM_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd8500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Subset(train, train_idx), batch_size=BATCH_SZ, shuffle=True)\n",
    "test_loader  = DataLoader(Subset(test,  test_idx),  batch_size=BATCH_SZ, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912504f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. Hiper‑parâmetros de RL / PQC ----------\n",
    "N_QUBITS   = 4\n",
    "MAX_DEPTH  = 8          # nº máximo de gates que o agente pode adicionar\n",
    "ACTION_SET = (['rx','ry','rz'] + ['cnot'])   # gates disponíveis\n",
    "N_ACTIONS  = len(ACTION_SET) * N_QUBITS\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=N_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888157c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitBuilderEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    State: Size Vector MAX_DEPTH*2\n",
    "        [gate_id_norm, wire_norm] each position(0 if None)\n",
    "    Action: int 0..N_ACTIONS-1 -> gate_id, wire_id\n",
    "    Reward: (0..1) in mini-batch using hibrid model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(N_ACTIONS)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(MAX_DEPTH*2,), dtype=np.float32)\n",
    "        #self.reset()\n",
    "        self.val_iter = iter(train_loader)\n",
    "\n",
    "    #--- building circuit --\n",
    "    def _add_gate(self, gate, wire):\n",
    "        self.circuit.append((gate, wire))\n",
    "    \n",
    "    def _encode_state(self):\n",
    "        vec = np.zeros((MAX_DEPTH*2,), dtype=np.float32)\n",
    "        print(f\"vec _encode_state {vec}\")\n",
    "        for i, (g,w) in enumerate(self.circuit):\n",
    "            g_id = ACTION_SET.index(g)\n",
    "            vec[i*2]   = g_id / len(ACTION_SET)\n",
    "            vec[i*2+1] = w / N_QUBITS\n",
    "        print(f\"vec _encode_state end {vec}\")\n",
    "        return vec\n",
    "    \n",
    "    #--QNode template (recompile each time reset) --\n",
    "    def _build_qnode(self):\n",
    "        def pqc(inputs, weights):\n",
    "            import torch\n",
    "            q_weights = weights.reshape(max_layers, n_qubits)\n",
    "            for q in range(N_QUBITS):\n",
    "                qml.RY(inputs[q], wires=q) # sample embedding\n",
    "\n",
    "            # gates generated by agent\n",
    "            for idx, (g,w) in enumerate(self.circuit):\n",
    "                if g == 'rx':\n",
    "                    qml.RX(q_weights[idx], wires=w)\n",
    "                elif g == 'ry':\n",
    "                    qml.RY(q_weights[idx], wires=w)\n",
    "                elif g == 'rz':\n",
    "                    qml.RZ(q_weights[idx], wires=w)\n",
    "                elif g == 'cnot':\n",
    "                    qml.CNOT(wires=[w, (w+1)%N_QUBITS])\n",
    "            print(f\"circuit: {self.circuit}\")\n",
    "            return [qml.expval(qml.PauliZ(w)) for w in range(N_QUBITS)]\n",
    "        return qml.QNode(pqc, dev, interface=\"torch\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8780c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Train RL agent --\n",
    "def train_agent():\n",
    "    env = CircuitBuilderEnv()\n",
    "\n",
    "    model_rl = PPO(\"MlpPolicy\", env, \n",
    "                    learning_rate=3e-4,n_steps=512,\n",
    "                    batch_size=64,gamma=0.95,\n",
    "                    verbose=1,seed=SEED)\n",
    "    \n",
    "    print(\"Training RL agent...\")\n",
    "    model_rl.learn(total_timesteps=10000)\n",
    "    model_rl.save(\"rl_agent\")\n",
    "    print(\"RL agent trained!\")\n",
    "    return model_rl\n",
    "\n",
    "#-- Test RL agent --\n",
    "def train_final_agent():\n",
    "    best_env = train_agent()\n",
    "    best_circuit = best_env.circuit\n",
    "\n",
    "    final_model = best_env._build_model().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=1e-3)\n",
    "\n",
    "    EPOCHS_SUP = 3 #upgrade to production\n",
    "    for epoch in range(EPOCHS_SUP):\n",
    "        final_model.train()\n",
    "        for image, labels in train_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            labels = labels.squeeze().long().to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = final_model(image)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #--Sample evaluation--\n",
    "        final_model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for image, labels in test_loader:\n",
    "                image = image.to(DEVICE)\n",
    "                labels = labels.squeeze().long().to(DEVICE)\n",
    "                logits = final_model(image)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS_SUP}, Test Accuracy: {acc:.4f}\")\n",
    "    print(\"Final model trained!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #-- Train RL agent --\n",
    "    train_agent()\n",
    "\n",
    "    #-- Train final model --\n",
    "    train_final_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fa595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea7951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
